{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batting collapse frequency. Are England unique?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Question:\n",
    "- How often do batting collapses happen?\n",
    "- Does England collapse more often that other teams?\n",
    "- Is this statement true? \"Joe Root rarely stops a collapse, and is often a part of it\"\n",
    "- Which players are best at stopping a collapse?\n",
    "\n",
    "\n",
    "### Methodology:\n",
    "- Create a table of fall of wicket:\n",
    "    - MatchID\n",
    "    - Date\n",
    "    - Batting team\n",
    "    - Bowling team\n",
    "    - Match type\n",
    "    - Innings\n",
    "    - Fall of Wicket 1 (runs, batsman)\n",
    "    - Fall of Wicket 2 (runs, batsman)\n",
    "    - etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem breakdown:\n",
    "- Data Source: howstat cricket scorecards\n",
    "- Extract Fall Of Wickets from a single game\n",
    "- Extract FoW from multiple games\n",
    "- Extract FoW from all (relevant) games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dateutil.parser import parse\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urllib.request.urlopen(\"http://howstat.com/cricket/Statistics/Matches/MatchScorecard.asp?MatchCode=2418\") as url:\n",
    "    s = url.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(s, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match Info\n",
    "def parse_match_info(html_scorecard):\n",
    "    \n",
    "    match_info_data = np.array([item.text.strip() for item in soup.find_all(class_=\"TextBlack8\")])[:5]\n",
    "    match_info_category = np.array([item.text.strip() for item in soup.find_all(class_=\"TextBlackBold8\")])[:5]\n",
    "\n",
    "    d_match_info = pd.DataFrame(match_info_data, match_info_category).T.to_dict(orient='records')[0]\n",
    "    d_match_info['Match Date:'] = parse(d_match_info['Match Date:']).date()\n",
    "    #print(d_match_info)\n",
    "    \n",
    "    return d_match_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_scorecard(innings_section):\n",
    "    \"\"\"\n",
    "    Takes a section of html containing the start of a scorecard, and builds a scorecard df upto and including the innings total.\n",
    "    \n",
    "    innings_section: bs4 object, which is of TextBlackBold8 class and contains the word \"Innings\" in its text.\n",
    "    returns:  df of scorecard, and innings name as string\n",
    "    \"\"\"\n",
    "    # The first parent is the header row of the scorecard\n",
    "    headers = [x.text.replace('\\xa0', ' ').strip() for x in innings_section.parent.find_all('td')]\n",
    "    \n",
    "    # We now want to loop through the siblings of the header row to get each batsman's scores, until we find the Total row,\n",
    "    # at which point we append the row then terminate.\n",
    "    nextNode = innings_section.parent\n",
    "    data = []\n",
    "    while True:\n",
    "        nextNode = nextNode.find_next_sibling() # use find_next_sibling() instead of next_sibling to avoid line breaks\n",
    "        row = [x.text.replace('\\xa0', ' ').replace('\\r', '').replace('\\n', '').strip() for x in nextNode.find_all('td')]\n",
    "\n",
    "        if 'Total' in row:\n",
    "            data.append(row)\n",
    "            break\n",
    "        else:\n",
    "            data.append(row)\n",
    "\n",
    "    innings_name = headers.pop(0).split('Innings')[0].strip()\n",
    "    headers.insert(0, 'Details')\n",
    "    headers.insert(0, 'Player')\n",
    "    df_scorecard = pd.DataFrame(data, columns=headers)\n",
    "    \n",
    "    \n",
    "    return innings_name, df_scorecard\n",
    "\n",
    "\n",
    "def parse_fall_of_wickets(fow_section):\n",
    "    \"\"\"\n",
    "    Takes a section of html containing the start of a fall of wickets section, and reads & reformats the FoW table.\n",
    "    \n",
    "    fow_section: bs4 object, a td element containing the words \"Fall of Wickets\"\n",
    "    returns: df of fall of wickets\n",
    "    \"\"\"\n",
    "    \n",
    "    table = fow_section.parent.find('table') # Move up one level and select table\n",
    "    td = table.find_all('td') # get table data\n",
    "    tab = []\n",
    "    \n",
    "    for x in td:\n",
    "        d_row = {}\n",
    "        row = x.text.strip().replace(u'\\xa0', u' ')\n",
    "        row = row.split(' ')\n",
    "        score = row[0].split('-')\n",
    "        d_row['Wicket'] = score[0]\n",
    "        d_row['Runs'] = score[1]\n",
    "        d_row['Player'] = row[-1]\n",
    "        tab.append(d_row)\n",
    "        \n",
    "    df_fow = pd.DataFrame(tab)\n",
    "        \n",
    "    return df_fow\n",
    "\n",
    "\n",
    "# Loop through each TextBlackBold8 element\n",
    "# If the text contains the word 'Innings', the next section will be the innings scorecard: so parse it.\n",
    "d_scorecards = {}\n",
    "l_innings = []\n",
    "for item in soup.find_all(class_=\"TextBlackBold8\"):\n",
    "    item_text = item.text.replace('\\xa0', ' ').strip()\n",
    "    if 'Innings' in item_text:\n",
    "        \n",
    "        # Extract the Innings number and Team\n",
    "        #l_innings.append(item_text.split('Innings')[0])\n",
    "        \n",
    "        # Go through siblings until the Total. This will be the batting scorecard\n",
    "        #print(item.parent.next_sibling)\n",
    "        #l_items.append(item)\n",
    "        \n",
    "        # parse the scorecard\n",
    "        innings, df_scorecard = parse_scorecard(item)\n",
    "        print(f'Parsed scorecard for: {innings} innings')\n",
    "        l_innings.append(innings)\n",
    "        \n",
    "        \n",
    "        d_scorecards[innings] = df_scorecard\n",
    "        \n",
    "        \n",
    "# Loop through each Fall of Wickets section, and parse the FoW record.   \n",
    "# Store in a dict with keys as innings names from parsed scorecard section.\n",
    "# This assumes there will always be a FoW for each scorecard\n",
    "l_fow = []\n",
    "fow_sections = soup.findAll(\"td\", text=re.compile('Fall of Wickets'))\n",
    "for item in fow_sections:\n",
    "    df_fow = parse_fall_of_wickets(item)\n",
    "    l_fow.append(df_fow)\n",
    "    print('Parsed FoW')\n",
    " \n",
    "# Convert list of FoW dfs to dict\n",
    "if len(l_fow) == len(l_innings):\n",
    "    print(f'There are {len(l_fow)} innings with fall of wicket data')\n",
    "    d_fow = {l_innings[i]: l_fow[i] for i in range(len(l_fow))}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_scorecards(d_scorecards):\n",
    "    # Combine scorecards dfs, add key column from the dict\n",
    "    df = pd.concat(d_scorecards, keys=l_innings).reset_index()\n",
    "\n",
    "    # Expand key column into Team, Innings columns. Add Date column.\n",
    "    meta = df.level_0.str.rsplit(n=1, expand=True)\n",
    "    df[['Team', 'Innings']] = meta\n",
    "    df = df.drop(['level_0'], axis=1)\n",
    "    df['MatchDate'] = d_match_info['Match Date:']\n",
    "\n",
    "    # Clean up column names and order\n",
    "    cols = list(df.columns)\n",
    "    cols = ['ScorecardIdx' if col == \"level_1\" else col for col in cols]\n",
    "    df.columns = cols\n",
    "    cols.insert(0, cols.pop(-2))\n",
    "    cols.insert(0, cols.pop(-2))\n",
    "    cols.insert(0, cols.pop(-1))\n",
    "    df = df[cols]\n",
    "\n",
    "    # Clean up data types\n",
    "    cols_numeric = ['ScorecardIdx', 'R', 'BF', '4s', '6s', 'SR']\n",
    "    df[cols_numeric] = df[cols_numeric].apply(pd.to_numeric, errors='coerce')\n",
    "    df['MatchDate'] = df['MatchDate'].apply(pd.to_datetime, errors='coerce', yearfirst=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_scorecards = clean_scorecards(d_scorecards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_fow(d_fow):\n",
    "    # Combine scorecards dfs, add key column from the dict\n",
    "    df = pd.concat(d_fow, keys=l_innings).reset_index()\n",
    "\n",
    "    # Expand key column into Team, Innings columns. Add Date column.\n",
    "    meta = df.level_0.str.rsplit(n=1, expand=True)\n",
    "    df[['Team', 'Innings']] = meta\n",
    "    df = df.drop(['level_0', 'level_1'], axis=1)\n",
    "    df['MatchDate'] = d_match_info['Match Date:']\n",
    "\n",
    "    # Clean up column names and order\n",
    "    cols = list(df.columns)\n",
    "    cols.insert(0, cols.pop(-2))\n",
    "    cols.insert(0, cols.pop(-2))\n",
    "    cols.insert(0, cols.pop(-1))\n",
    "    df = df[cols]\n",
    "\n",
    "    # Clean up data types\n",
    "    cols_numeric = ['Wicket', 'Runs']\n",
    "    df[cols_numeric] = df[cols_numeric].apply(pd.to_numeric, errors='coerce')\n",
    "    df['MatchDate'] = df['MatchDate'].apply(pd.to_datetime, errors='coerce', yearfirst=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_fow = clean_fow(d_fow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scorecards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FoW\n",
    "\"\"\"HTML structure:\n",
    "1 large table, contains: \n",
    "    innings + team name\n",
    "    innings scorecard\n",
    "    fall of wickets\n",
    "    innings + team name\n",
    "    innings scorecard\n",
    "    fall of wickets\n",
    "    \n",
    "    etc.\n",
    "    \n",
    "    \n",
    "Procedure:\n",
    "Get this table:\n",
    "    Read innings + team name (s)\n",
    "    Read the scorecard (s)\n",
    "    Read the FoW (s)\n",
    "    Split by innings + team name.\n",
    "Reformat into readable table\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
